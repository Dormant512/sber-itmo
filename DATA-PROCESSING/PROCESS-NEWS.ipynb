{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64288b10",
   "metadata": {},
   "source": [
    "# BERTopic news processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec57a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/dormant/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, timedelta, datetime\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 7.5]\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "#plt.style.use('dark_background')\n",
    "\n",
    "comma_strip = lambda x: x.rstrip(\",\")\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "\n",
    "mystem = Mystem() \n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = mystem.lemmatize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords \\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation\n",
    "              and token.strip() not in [\"«\", \"»\", \"“\", \"”\"]]\n",
    "    text = \" \".join(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c95ff6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    news = pd.read_csv('../DATA-MINING/SCRAPED-DATA/LEMM-NEWS-2018-1-1-2022-9-1.csv',\n",
    "                       sep='\\t',\n",
    "                       on_bad_lines='skip')\n",
    "except:\n",
    "    news = pd.read_csv('../DATA-MINING/SCRAPED-DATA/NEWS-2018-1-1-2022-9-1.csv',\n",
    "                       sep='\\t',\n",
    "                       on_bad_lines='skip')\n",
    "    news['title'] = news['title'].apply(preprocess_text)\n",
    "    news.to_csv('../DATA-MINING/SCRAPED-DATA/LEMM-NEWS-2018-1-1-2022-9-1.csv',\n",
    "                sep='\\t',\n",
    "                index=False)\n",
    "    \n",
    "    # validate working file\n",
    "    news = pd.read_csv('../DATA-MINING/SCRAPED-DATA/LEMM-NEWS-2018-1-1-2022-9-1.csv',\n",
    "                       sep='\\t',\n",
    "                       on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a159e4a5",
   "metadata": {},
   "source": [
    "# DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "470175cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#news = news.iloc[:40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c72cd65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of news headers: 411713\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>потанин оставаться вода</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>автор хит 1 1 устраивать праздничный переполох</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>северный корея принимать участие олимпиада южный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>зимний сказка петербург продлиться недолго</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>алкогольный энергетик показывать красный свет</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                             title\n",
       "0  2018-01-01                           потанин оставаться вода\n",
       "1  2018-01-01    автор хит 1 1 устраивать праздничный переполох\n",
       "2  2018-01-01  северный корея принимать участие олимпиада южный\n",
       "3  2018-01-01        зимний сказка петербург продлиться недолго\n",
       "4  2018-01-01     алкогольный энергетик показывать красный свет"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Number of news headers: {len(news)}')\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e835f77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 2018-01-01 to 2022-09-01\n",
      "Number of days: 1704\n",
      "243 is going to be the number of weekly bins.\n"
     ]
    }
   ],
   "source": [
    "datify = lambda x: datetime.strptime(x, '%Y-%m-%d')\n",
    "textify = lambda x: x.strftime('%Y-%m-%d')\n",
    "\n",
    "start_d, end_d = datify(min(news['date'])), datify(max(news['date']))\n",
    "delta_d = end_d - start_d\n",
    "num_days = delta_d.days\n",
    "\n",
    "print(f\"From {textify(start_d)} to {textify(end_d)}\")\n",
    "print(f\"Number of days: {num_days}\")\n",
    "\n",
    "num_bins = int(num_days/7)\n",
    "print(f\"{num_bins} is going to be the number of weekly bins.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6019603f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>411708</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>петербуржец напоминать изменяться общественный...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411709</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>обгорать трешка проспект наука вытаскивать пос...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411710</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>называть креативный двор санкт-петербург котор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411711</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>первый сентябрь петербург открываться 7 социал...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411712</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>гороскоп весь знак зодиак 1 сентябрь 2022 год ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date                                              title\n",
       "411708  2022-09-01  петербуржец напоминать изменяться общественный...\n",
       "411709  2022-09-01  обгорать трешка проспект наука вытаскивать пос...\n",
       "411710  2022-09-01  называть креативный двор санкт-петербург котор...\n",
       "411711  2022-09-01  первый сентябрь петербург открываться 7 социал...\n",
       "411712  2022-09-01  гороскоп весь знак зодиак 1 сентябрь 2022 год ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa2b5fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 17:52:08.727874: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-06 17:52:09.074406: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-06 17:52:09.074431: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-06-06 17:52:09.131681: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-06 17:52:10.146168: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-06 17:52:10.146686: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-06 17:52:10.146695: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9e040981dc42ef958870fb2d59998e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12867 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 19:33:14,281 - BERTopic - Transformed documents to Embeddings\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Topics to visualize (-2 to include all)\n",
    "num_of_topics = -2\n",
    "\n",
    "# Number of topics after reduction\n",
    "reduce_topics_to = 50\n",
    "\n",
    "# Start topic\n",
    "start_topic = 2\n",
    "\n",
    "timestamps = news['date'].to_list()\n",
    "titles = news['title'].to_list()\n",
    "\n",
    "try:\n",
    "    topic_df = pd.read_csv('./PROCESSED-DATA/TOPICS.csv', sep=',', on_bad_lines='skip')\n",
    "    topic_df.rename(columns={\"Unnamed: 0\": \"Date\"}, inplace=True)\n",
    "    topic_df.set_index('Date', inplace=True)\n",
    "    topic_df.index = topic_df.index.map(datify)\n",
    "    topic_df = topic_df.iloc[:,start_topic:num_of_topics+1]\n",
    "except:\n",
    "    topic_model = BERTopic(embedding_model='distiluse-base-multilingual-cased-v1',\n",
    "                           verbose=True)\n",
    "    topics, probs = topic_model.fit_transform(titles)\n",
    "    topic_model.reduce_topics(titles, nr_topics=reduce_topics_to)\n",
    "    topic_labels = topic_model.generate_topic_labels(nr_words=3,\n",
    "                                                     topic_prefix=True,\n",
    "                                                     word_length=10,\n",
    "                                                     separator=\"_\")\n",
    "    \n",
    "    topics_over_time = topic_model.topics_over_time(titles, timestamps, nr_bins=num_bins)\n",
    "    topic_df = pd.DataFrame(topics_over_time)\n",
    "    topic_df.rename(columns={\"Timestamp\": \"Date\"}, inplace=True)\n",
    "    topic_df.fillna(0.0, inplace=True)\n",
    "    \n",
    "    new_index = pd.date_range(start=textify(start_d),\n",
    "                              end=textify(end_d + relativedelta(months=-1)),\n",
    "                              freq='MS')\n",
    "    \n",
    "    topic_df = topic_df.pivot(index=\"Date\",\n",
    "                              columns=\"Topic\",\n",
    "                              values=\"Frequency\")\n",
    "    \n",
    "    topic_df = topic_df.reindex(topic_df.index.union(new_index)).interpolate(method='time')\n",
    "    topic_df = topic_df.reindex(new_index)\n",
    "    topic_df.set_axis(topic_labels, axis=1, inplace=True)\n",
    "    topic_df.fillna(0.0, inplace=True)\n",
    "    \n",
    "    topic_df.to_csv('./PROCESSED-DATA/TOPICS.csv', sep=',')\n",
    "    \n",
    "    # validate working file\n",
    "    topic_df = pd.read_csv('./PROCESSED-DATA/TOPICS.csv', sep=',', on_bad_lines='skip')\n",
    "    topic_df.rename(columns={\"Unnamed: 0\": \"Date\"}, inplace=True)\n",
    "    topic_df.set_index('Date', inplace=True)\n",
    "    topic_df.index = topic_df.index.map(datify)\n",
    "    topic_df = topic_df.iloc[:,start_topic:num_of_topics+1]\n",
    "    \n",
    "print(f\"Number of topics: {len(topic_df.columns)}\")\n",
    "plt.plot(topic_df);\n",
    "if len(topic_df.columns) <= 35:\n",
    "    plt.legend(topic_df.columns);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c1de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a5e6e1",
   "metadata": {},
   "source": [
    "## Take only TS with peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eadef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.tsa.api as smt\n",
    "\n",
    "# Desired number of topics\n",
    "desired_topics = 20\n",
    "\n",
    "for threshold in np.arange(10.0, 0.1, -0.1):\n",
    "    non_stat_topic_df = topic_df.copy()\n",
    "    for col in non_stat_topic_df.columns:\n",
    "        if non_stat_topic_df[col].max() / non_stat_topic_df[col].mean() < threshold:\n",
    "            non_stat_topic_df = non_stat_topic_df.drop(columns=[col])\n",
    "    # If num of topics is desired += 10%\n",
    "    if np.abs(len(non_stat_topic_df.columns) - desired_topics) <= (desired_topics / 10):\n",
    "        break\n",
    "\n",
    "plt.plot(non_stat_topic_df);\n",
    "plt.legend(non_stat_topic_df.columns);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
